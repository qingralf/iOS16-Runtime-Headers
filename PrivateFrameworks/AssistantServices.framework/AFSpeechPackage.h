/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
 */

@interface AFSpeechPackage : NSObject <NSCopying, NSSecureCoding> {
    AFSpeechAudioAnalytics * _audioAnalytics;
    bool  _isFinal;
    AFSpeechLatticeMitigatorResult * _latticeMitigatorResult;
    AFSpeechRecognition * _rawRecognition;
    AFSpeechRecognition * _recognition;
    bool  _recognitionPaused;
    long long  _resultCandidateId;
    bool  _speechProfileUsed;
    AFSpeechRecognition * _unfilteredRecognition;
    double  _utteranceStart;
}

@property (nonatomic, readonly) AFSpeechAudioAnalytics *audioAnalytics;
@property (nonatomic, readonly) bool isFinal;
@property (nonatomic, readonly) AFSpeechLatticeMitigatorResult *latticeMitigatorResult;
@property (nonatomic, readonly) AFSpeechRecognition *rawRecognition;
@property (nonatomic, readonly) AFSpeechRecognition *recognition;
@property (nonatomic, readonly) bool recognitionPaused;
@property (nonatomic, readonly) long long resultCandidateId;
@property (nonatomic, readonly) bool speechProfileUsed;
@property (nonatomic, readonly) AFSpeechRecognition *unfilteredRecognition;
@property (nonatomic, readonly) double utteranceStart;

+ (bool)supportsSecureCoding;

- (void).cxx_destruct;
- (id)audioAnalytics;
- (id)copyWithZone:(struct _NSZone { }*)arg1;
- (id)dictionaryRepresentation;
- (void)encodeWithCoder:(id)arg1;
- (id)initWithCoder:(id)arg1;
- (id)initWithRecognition:(id)arg1 rawRecognition:(id)arg2 audioAnalytics:(id)arg3 isFinal:(bool)arg4 utteranceStart:(double)arg5;
- (id)initWithRecognition:(id)arg1 rawRecognition:(id)arg2 audioAnalytics:(id)arg3 isFinal:(bool)arg4 utteranceStart:(double)arg5 latticeMitigatorResult:(id)arg6;
- (id)initWithRecognition:(id)arg1 unfilteredRecognition:(id)arg2 rawRecognition:(id)arg3 audioAnalytics:(id)arg4 isFinal:(bool)arg5 utteranceStart:(double)arg6;
- (id)initWithRecognition:(id)arg1 unfilteredRecognition:(id)arg2 rawRecognition:(id)arg3 audioAnalytics:(id)arg4 isFinal:(bool)arg5 utteranceStart:(double)arg6 latticeMitigatorResult:(id)arg7;
- (id)initWithRecognition:(id)arg1 unfilteredRecognition:(id)arg2 rawRecognition:(id)arg3 audioAnalytics:(id)arg4 isFinal:(bool)arg5 utteranceStart:(double)arg6 latticeMitigatorResult:(id)arg7 recognitionPaused:(bool)arg8;
- (id)initWithRecognition:(id)arg1 unfilteredRecognition:(id)arg2 rawRecognition:(id)arg3 audioAnalytics:(id)arg4 isFinal:(bool)arg5 utteranceStart:(double)arg6 latticeMitigatorResult:(id)arg7 recognitionPaused:(bool)arg8 speechProfileUsed:(bool)arg9;
- (id)initWithRecognition:(id)arg1 unfilteredRecognition:(id)arg2 rawRecognition:(id)arg3 audioAnalytics:(id)arg4 isFinal:(bool)arg5 utteranceStart:(double)arg6 latticeMitigatorResult:(id)arg7 recognitionPaused:(bool)arg8 speechProfileUsed:(bool)arg9 resultCandidateId:(long long)arg10;
- (bool)isFinal;
- (id)latticeMitigatorResult;
- (id)rawRecognition;
- (id)recognition;
- (bool)recognitionPaused;
- (long long)resultCandidateId;
- (bool)speechProfileUsed;
- (id)unfilteredRecognition;
- (double)utteranceStart;

@end
